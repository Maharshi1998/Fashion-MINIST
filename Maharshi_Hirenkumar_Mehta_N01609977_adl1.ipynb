{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"dockerImageVersionId":30647,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import FashionMNIST\nfrom torchvision.transforms import Resize, ToTensor, Normalize, RandomRotation, RandomHorizontalFlip\nfrom sklearn.metrics import classification_report\nfrom torchvision import transforms ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-07T23:41:12.988802Z","iopub.execute_input":"2024-02-07T23:41:12.989223Z","iopub.status.idle":"2024-02-07T23:41:38.273111Z","shell.execute_reply.started":"2024-02-07T23:41:12.989186Z","shell.execute_reply":"2024-02-07T23:41:38.272170Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = FashionMNIST(root='./data', train=True, download=True,\n                             transform=transforms.Compose([\n                                 Resize((64, 64)),\n                                 RandomRotation(15),  # Random rotation up to 15 degrees\n                                 RandomHorizontalFlip(),  # Random horizontal flip\n                                 ToTensor(),\n                                 Normalize((0.5,), (0.5,))\n                             ]))\n\ntest_dataset = FashionMNIST(root='./data', train=False, download=True,\n                            transform=transforms.Compose([\n                                Resize((64, 64)),\n                                ToTensor(),\n                                Normalize((0.5,), (0.5,))\n                            ]))","metadata":{"execution":{"iopub.status.busy":"2024-02-07T23:41:38.274919Z","iopub.execute_input":"2024-02-07T23:41:38.275287Z","iopub.status.idle":"2024-02-07T23:41:43.279443Z","shell.execute_reply.started":"2024-02-07T23:41:38.275259Z","shell.execute_reply":"2024-02-07T23:41:43.278529Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 26421880/26421880 [00:01<00:00, 16461474.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29515/29515 [00:00<00:00, 295578.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4422102/4422102 [00:00<00:00, 5524677.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5148/5148 [00:00<00:00, 11275340.47it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-07T23:41:43.280698Z","iopub.execute_input":"2024-02-07T23:41:43.281052Z","iopub.status.idle":"2024-02-07T23:41:43.285325Z","shell.execute_reply.started":"2024-02-07T23:41:43.281018Z","shell.execute_reply":"2024-02-07T23:41:43.284635Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class ImprovedANN(nn.Module):\n    def __init__(self):\n        super(ImprovedANN, self).__init__()\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(64 * 64, 2048)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(2048, 1024)\n        self.relu2 = nn.ReLU()\n        self.fc3 = nn.Linear(1024, 512)\n        self.relu3 = nn.ReLU()\n        self.fc4 = nn.Linear(512, 256)\n        self.relu4 = nn.ReLU()\n        self.fc5 = nn.Linear(256, 128)\n        self.relu5 = nn.ReLU()\n        self.fc6 = nn.Linear(128, 64)\n        self.relu6 = nn.ReLU()\n        self.fc7 = nn.Linear(64, 10)\n\n    def forward(self, x):\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.relu1(x)\n        x = self.fc2(x)\n        x = self.relu2(x)\n        x = self.fc3(x)\n        x = self.relu3(x)\n        x = self.fc4(x)\n        x = self.relu4(x)\n        x = self.fc5(x)\n        x = self.relu5(x)\n        x = self.fc6(x)\n        x = self.relu6(x)\n        x = self.fc7(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-02-07T23:41:43.286234Z","iopub.execute_input":"2024-02-07T23:41:43.286495Z","iopub.status.idle":"2024-02-07T23:41:43.300600Z","shell.execute_reply.started":"2024-02-07T23:41:43.286468Z","shell.execute_reply":"2024-02-07T23:41:43.299943Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def train(model, criterion, optimizer, train_loader):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for inputs, labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    train_loss = running_loss / len(train_loader)\n    train_accuracy = correct / total\n    return train_loss, train_accuracy\n\ndef evaluate(model, criterion, data_loader):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    predictions = []\n\n    with torch.no_grad():\n        for inputs, labels in data_loader:\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n            predictions.extend(predicted.tolist())\n\n    loss = running_loss / len(data_loader)\n    accuracy = correct / total\n    return loss, accuracy, predictions\n","metadata":{"execution":{"iopub.status.busy":"2024-02-07T23:41:43.302325Z","iopub.execute_input":"2024-02-07T23:41:43.302586Z","iopub.status.idle":"2024-02-07T23:41:43.315693Z","shell.execute_reply.started":"2024-02-07T23:41:43.302560Z","shell.execute_reply":"2024-02-07T23:41:43.315126Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"improved_model = ImprovedANN()","metadata":{"execution":{"iopub.status.busy":"2024-02-07T23:41:43.316475Z","iopub.execute_input":"2024-02-07T23:41:43.316694Z","iopub.status.idle":"2024-02-07T23:41:43.424889Z","shell.execute_reply.started":"2024-02-07T23:41:43.316671Z","shell.execute_reply":"2024-02-07T23:41:43.424166Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(improved_model.parameters(), lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T23:41:43.425803Z","iopub.execute_input":"2024-02-07T23:41:43.426040Z","iopub.status.idle":"2024-02-07T23:41:43.429885Z","shell.execute_reply.started":"2024-02-07T23:41:43.426016Z","shell.execute_reply":"2024-02-07T23:41:43.429289Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for epoch in range(85):  # Train for 10 epochs\n    train_loss, train_accuracy = train(improved_model, criterion, optimizer, train_loader)\n    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-07T23:58:34.340596Z","iopub.execute_input":"2024-02-07T23:58:34.340922Z","iopub.status.idle":"2024-02-08T01:31:54.492756Z","shell.execute_reply.started":"2024-02-07T23:58:34.340890Z","shell.execute_reply":"2024-02-08T01:31:54.491877Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1: Train Loss: 0.3032, Train Accuracy: 0.8861\nEpoch 2: Train Loss: 0.2971, Train Accuracy: 0.8895\nEpoch 3: Train Loss: 0.2887, Train Accuracy: 0.8902\nEpoch 4: Train Loss: 0.2861, Train Accuracy: 0.8923\nEpoch 5: Train Loss: 0.2797, Train Accuracy: 0.8947\nEpoch 6: Train Loss: 0.2722, Train Accuracy: 0.8972\nEpoch 7: Train Loss: 0.2702, Train Accuracy: 0.8977\nEpoch 8: Train Loss: 0.2615, Train Accuracy: 0.9013\nEpoch 9: Train Loss: 0.2600, Train Accuracy: 0.9026\nEpoch 10: Train Loss: 0.2543, Train Accuracy: 0.9050\nEpoch 11: Train Loss: 0.2487, Train Accuracy: 0.9057\nEpoch 12: Train Loss: 0.2455, Train Accuracy: 0.9070\nEpoch 13: Train Loss: 0.2393, Train Accuracy: 0.9096\nEpoch 14: Train Loss: 0.2371, Train Accuracy: 0.9105\nEpoch 15: Train Loss: 0.2319, Train Accuracy: 0.9112\nEpoch 16: Train Loss: 0.2264, Train Accuracy: 0.9152\nEpoch 17: Train Loss: 0.2222, Train Accuracy: 0.9156\nEpoch 18: Train Loss: 0.2171, Train Accuracy: 0.9168\nEpoch 19: Train Loss: 0.2153, Train Accuracy: 0.9176\nEpoch 20: Train Loss: 0.2077, Train Accuracy: 0.9205\nEpoch 21: Train Loss: 0.2050, Train Accuracy: 0.9220\nEpoch 22: Train Loss: 0.2038, Train Accuracy: 0.9222\nEpoch 23: Train Loss: 0.1950, Train Accuracy: 0.9267\nEpoch 24: Train Loss: 0.1915, Train Accuracy: 0.9275\nEpoch 25: Train Loss: 0.1867, Train Accuracy: 0.9292\nEpoch 26: Train Loss: 0.1813, Train Accuracy: 0.9304\nEpoch 27: Train Loss: 0.1781, Train Accuracy: 0.9321\nEpoch 28: Train Loss: 0.1764, Train Accuracy: 0.9325\nEpoch 29: Train Loss: 0.1694, Train Accuracy: 0.9349\nEpoch 30: Train Loss: 0.1635, Train Accuracy: 0.9380\nEpoch 31: Train Loss: 0.1626, Train Accuracy: 0.9370\nEpoch 32: Train Loss: 0.1573, Train Accuracy: 0.9390\nEpoch 33: Train Loss: 0.1548, Train Accuracy: 0.9401\nEpoch 34: Train Loss: 0.1493, Train Accuracy: 0.9427\nEpoch 35: Train Loss: 0.1482, Train Accuracy: 0.9430\nEpoch 36: Train Loss: 0.1436, Train Accuracy: 0.9451\nEpoch 37: Train Loss: 0.1387, Train Accuracy: 0.9465\nEpoch 38: Train Loss: 0.1365, Train Accuracy: 0.9472\nEpoch 39: Train Loss: 0.1343, Train Accuracy: 0.9482\nEpoch 40: Train Loss: 0.1291, Train Accuracy: 0.9499\nEpoch 41: Train Loss: 0.1256, Train Accuracy: 0.9514\nEpoch 42: Train Loss: 0.1239, Train Accuracy: 0.9524\nEpoch 43: Train Loss: 0.1191, Train Accuracy: 0.9544\nEpoch 44: Train Loss: 0.1182, Train Accuracy: 0.9546\nEpoch 45: Train Loss: 0.1119, Train Accuracy: 0.9573\nEpoch 46: Train Loss: 0.1111, Train Accuracy: 0.9576\nEpoch 47: Train Loss: 0.1093, Train Accuracy: 0.9578\nEpoch 48: Train Loss: 0.1086, Train Accuracy: 0.9577\nEpoch 49: Train Loss: 0.1030, Train Accuracy: 0.9611\nEpoch 50: Train Loss: 0.0993, Train Accuracy: 0.9619\nEpoch 51: Train Loss: 0.0979, Train Accuracy: 0.9631\nEpoch 52: Train Loss: 0.1017, Train Accuracy: 0.9609\nEpoch 53: Train Loss: 0.0927, Train Accuracy: 0.9638\nEpoch 54: Train Loss: 0.0927, Train Accuracy: 0.9640\nEpoch 55: Train Loss: 0.0904, Train Accuracy: 0.9653\nEpoch 56: Train Loss: 0.0896, Train Accuracy: 0.9657\nEpoch 57: Train Loss: 0.0890, Train Accuracy: 0.9662\nEpoch 58: Train Loss: 0.0848, Train Accuracy: 0.9687\nEpoch 59: Train Loss: 0.0852, Train Accuracy: 0.9679\nEpoch 60: Train Loss: 0.0823, Train Accuracy: 0.9694\nEpoch 61: Train Loss: 0.0787, Train Accuracy: 0.9711\nEpoch 62: Train Loss: 0.0802, Train Accuracy: 0.9695\nEpoch 63: Train Loss: 0.0779, Train Accuracy: 0.9712\nEpoch 64: Train Loss: 0.0766, Train Accuracy: 0.9707\nEpoch 65: Train Loss: 0.0733, Train Accuracy: 0.9719\nEpoch 66: Train Loss: 0.0723, Train Accuracy: 0.9724\nEpoch 67: Train Loss: 0.0729, Train Accuracy: 0.9723\nEpoch 68: Train Loss: 0.0708, Train Accuracy: 0.9731\nEpoch 69: Train Loss: 0.0701, Train Accuracy: 0.9740\nEpoch 70: Train Loss: 0.0654, Train Accuracy: 0.9751\nEpoch 71: Train Loss: 0.0671, Train Accuracy: 0.9751\nEpoch 72: Train Loss: 0.0694, Train Accuracy: 0.9744\nEpoch 73: Train Loss: 0.0658, Train Accuracy: 0.9756\nEpoch 74: Train Loss: 0.0600, Train Accuracy: 0.9770\nEpoch 75: Train Loss: 0.0628, Train Accuracy: 0.9756\nEpoch 76: Train Loss: 0.0608, Train Accuracy: 0.9776\nEpoch 77: Train Loss: 0.0620, Train Accuracy: 0.9766\nEpoch 78: Train Loss: 0.0612, Train Accuracy: 0.9774\nEpoch 79: Train Loss: 0.0592, Train Accuracy: 0.9783\nEpoch 80: Train Loss: 0.0558, Train Accuracy: 0.9788\nEpoch 81: Train Loss: 0.0555, Train Accuracy: 0.9795\nEpoch 82: Train Loss: 0.0558, Train Accuracy: 0.9795\nEpoch 83: Train Loss: 0.0555, Train Accuracy: 0.9794\nEpoch 84: Train Loss: 0.0547, Train Accuracy: 0.9794\nEpoch 85: Train Loss: 0.0545, Train Accuracy: 0.9795\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loss, test_accuracy, predictions = evaluate(improved_model, criterion, test_loader)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n\n# Step 9: Print the classification report\ntrue_labels = [label for _, label in test_dataset]\nprint(classification_report(true_labels, predictions))","metadata":{"execution":{"iopub.status.busy":"2024-02-08T01:32:41.414060Z","iopub.execute_input":"2024-02-08T01:32:41.414441Z","iopub.status.idle":"2024-02-08T01:32:47.304951Z","shell.execute_reply.started":"2024-02-08T01:32:41.414409Z","shell.execute_reply":"2024-02-08T01:32:47.304154Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Test Loss: 0.6762, Test Accuracy: 0.8875\n              precision    recall  f1-score   support\n\n           0       0.83      0.82      0.83      1000\n           1       0.98      0.98      0.98      1000\n           2       0.82      0.82      0.82      1000\n           3       0.89      0.90      0.89      1000\n           4       0.82      0.79      0.81      1000\n           5       0.98      0.96      0.97      1000\n           6       0.70      0.72      0.71      1000\n           7       0.94      0.95      0.95      1000\n           8       0.96      0.97      0.97      1000\n           9       0.96      0.96      0.96      1000\n\n    accuracy                           0.89     10000\n   macro avg       0.89      0.89      0.89     10000\nweighted avg       0.89      0.89      0.89     10000\n\n","output_type":"stream"}]}]}